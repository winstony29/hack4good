---
phase: 02-experience-lead
plan: 02
type: execute
domain: accessibility-backend
---

<objective>
Implement the Text-to-Speech (TTS) backend endpoint using ElevenLabs API.

Purpose: Enable visually impaired users to hear activity descriptions and UI content read aloud.
Output: Working /accessibility/tts endpoint that returns audio (mock or real ElevenLabs).
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-phase.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

**Existing backend infrastructure:**
@backend/app/integrations/elevenlabs_client.py
@backend/app/api/accessibility.py
@backend/app/core/config.py

**Key patterns:**
- ElevenLabsClient stub exists with generate_speech method
- API endpoint stub exists at /accessibility/tts (returns 501)
- Settings already include ELEVENLABS_API_KEY (optional)
- When API key is missing, should return mock audio data
- Frontend TTSButton.jsx already calls this endpoint

**Frontend consumer:**
@frontend/src/components/accessibility/TTSButton.jsx
@frontend/src/contexts/AccessibilityContext.jsx
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement ElevenLabs client with fallback mock</name>
  <files>backend/app/integrations/elevenlabs_client.py</files>
  <action>
Complete the ElevenLabs client implementation:

1. Add proper import for elevenlabs library (already in requirements.txt)
2. Implement generate_speech method:
   - If ELEVENLABS_API_KEY is set, call the real API
   - If not set, return a mock audio data URL
3. Use eleven_multilingual_v2 model for multi-language support
4. Handle errors gracefully - return mock on failure
5. Map language codes to appropriate voices:
   - en -> Rachel (English)
   - zh -> Use multilingual model (will work)
   - ms/ta -> Use multilingual model

Mock fallback should return: "data:audio/mp3;base64,{small_valid_base64}"
For demo, we can use a tiny valid MP3 base64 or just indicate mock mode.
  </action>
  <verify>Python syntax check: `python -c "from app.integrations.elevenlabs_client import ElevenLabsClient; print('OK')"`</verify>
  <done>ElevenLabsClient can generate speech with real API or mock fallback</done>
</task>

<task type="auto">
  <name>Task 2: Wire TTS endpoint to use ElevenLabs client</name>
  <files>backend/app/api/accessibility.py</files>
  <action>
Update the /accessibility/tts endpoint:

1. Import and instantiate ElevenLabsClient
2. In text_to_speech function:
   - Get text and language from request
   - Call elevenlabs_client.generate_speech(text, language)
   - Return the audio URL/data in response
3. Remove the HTTPException(501) - endpoint should work now
4. Return proper TTSResponse with audio_url and estimated duration
5. Duration can be estimated: ~150ms per word (rough estimate)

Handle edge cases:
- Empty text -> Return error 400
- Very long text -> Truncate to 5000 chars max
  </action>
  <verify>curl -X POST "http://localhost:8000/accessibility/tts" -H "Content-Type: application/json" -d '{"text":"Hello world","language":"en"}' (needs backend running)</verify>
  <done>TTS endpoint returns audio data instead of 501 error</done>
</task>

<task type="auto">
  <name>Task 3: Add mock audio file for demo mode</name>
  <files>backend/app/utils/mock_audio.py</files>
  <action>
Create a utility module with a small valid MP3 audio as base64:

1. Create mock_audio.py with a function get_mock_audio_base64()
2. Include a tiny valid MP3 file as base64 string (a short "beep" or silence)
3. This ensures the frontend audio player doesn't error on mock mode
4. Update ElevenLabsClient to use this mock instead of placeholder string

Alternative: Generate a text that says "[TTS Mock Mode]" using browser speech synthesis on frontend if audio fails.

The mock should be a valid audio data URL that the browser can play.
  </action>
  <verify>Python import test: `python -c "from app.utils.mock_audio import get_mock_audio_base64; print(len(get_mock_audio_base64()))"`</verify>
  <done>Mock audio utility exists for demo/dev mode</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] Backend starts without errors: `cd backend && python -m uvicorn app.main:app --reload`
- [ ] Endpoint responds: `curl -X POST localhost:8000/accessibility/tts -H "Content-Type: application/json" -d '{"text":"test","language":"en"}'`
- [ ] Response includes audio_url field
- [ ] No 501 error returned
</verification>

<success_criteria>

- ElevenLabsClient.generate_speech() works with mock fallback
- /accessibility/tts endpoint returns audio data
- Frontend TTSButton can call endpoint and receive response
- Works without ELEVENLABS_API_KEY (mock mode)
- Works with ELEVENLABS_API_KEY (real mode) if available
</success_criteria>

<output>
After completion, create `.planning/phases/02-experience-lead/02-02-SUMMARY.md`
</output>
